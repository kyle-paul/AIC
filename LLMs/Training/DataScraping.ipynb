{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import bs4 as bs\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_only_text(url):\n",
    "    page=urlopen(url)\n",
    "    soup=bs.BeautifulSoup(page,\"lxml\")\n",
    "    text =''.join(map(lambda p: p.text, soup.find_all('p')))\n",
    "    return soup.title.text, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_website(url):\n",
    "    try:\n",
    "        # Send a GET request to the specified URL\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check for any errors in the HTTP request\n",
    "\n",
    "        # Parse the HTML content of the page using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Extract information based on your requirements\n",
    "\n",
    "        # Title\n",
    "        title = soup.title.string\n",
    "        print(f\"Title: {title}\")\n",
    "\n",
    "        # Body Content\n",
    "        body_content = soup.body.get_text() if soup.body else \"N/A\"\n",
    "        print(f\"Body Content: {body_content}\")\n",
    "\n",
    "        # Headers (<h> tags)\n",
    "        headers = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "        for header in headers:\n",
    "            print(f\"Header: {header.name} - {header.text}\")\n",
    "\n",
    "        # Meta tags\n",
    "        meta_tags = soup.find_all('meta')\n",
    "        for meta_tag in meta_tags:\n",
    "            print(f\"Meta Tag: {meta_tag}\")\n",
    "\n",
    "        # Description (from meta tag)\n",
    "        description = soup.find('meta', attrs={'name': 'description'})\n",
    "        description_content = description['content'] if description else \"N/A\"\n",
    "        print(f\"Description: {description_content}\")\n",
    "\n",
    "        # Alt attributes in images\n",
    "        images = soup.find_all('img')\n",
    "        for img in images:\n",
    "            alt_text = img.get('alt', \"N/A\")\n",
    "            print(f\"Image Alt: {alt_text}\")\n",
    "\n",
    "        # You can add more code here to extract other information from the page\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.footlocker.com/category/sport/basketball/shoes/best-basketball-shoes.html\"\n",
    "scrape_website(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
